{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part1. K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>KNN is a form of <i>instance</i>, or <i>memory</i> based learning wherein we don't learn a function $f(X)$ to estimate $E[Y|X]$. It is a nonlinear, nonparametric model. To make a classification for a given instance $\\mathbf{x}^{(i)}$, we search the training data for the $k$-nearest neighbors, as defined by some distance metric $d(\\mathbf{x}^{(i)},\\mathbf{x}^{(j)})$. The estimate of $h_{k,\\cal{D}}(\\mathbf{x})$ is then given by:<br><br>\n",
    "\n",
    "<center>$h_{k,\\cal{D}}(\\mathbf{x}) = \\underset{j}{\\operatorname{argmax}}\\big({\\frac{1}{k} \\sum\\limits_{i \\in \\cal{N_k(\\mathbf{x})}}} \\mathbb{1}\\{y^{(i)}=j\\}\\big)$</center><br><br>\n",
    "\n",
    "<center>where $\\cal{N_{k}(\\mathbf{x})} = \\{x^{(j)}\\in\\cal{D} \\text{: k closest points to } \\mathbf{x} \\text{ in } \\cal{D}\\}$</center>\n",
    "\n",
    "<br>\n",
    "So, we need a distance metric to determine closest points. The most common distance function used in k-NN is the <i>Euclidean Distance</i>.<br><br>\n",
    "\n",
    "Let $\\mathbf{x} = <x_1,...x_p>$ be a $p$-dimensional vector, then for two instances $i \\text{ and } j$:<br><br>\n",
    "<center>$eud(\\mathbf{x}^{(i)},\\mathbf{x}^{(j)}) = \\sqrt{(x_1^{(i)}-x_1^{(j)})^2+...+(x_p^{(i)}-x_p^{(j)})^2} = \\sqrt{\\sum\\limits_{t=1}^p (x_t^{(i)}-x_t^{(j)})^2}$\n",
    "</center>\n",
    "<br><br>\n",
    "\n",
    "See here for implementation details, \n",
    "(https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.spatial.distance \n",
    "import math\n",
    "\n",
    "from IPython.display import Image\n",
    "from sklearn.preprocessing import scale \n",
    "# from sklearn.grid_search import GridSearchCV\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from YourAnswer import crossValidation_Ridge,crossValidation_Lasso\n",
    "from YourAnswer import predictKNN\n",
    "from utils import plotData, vis_decision_boundary, vis_coef, vis_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what does the data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"ex2data1.txt\", header=None, names=['test1', 'test2', 'accepted'])\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax = plotData(data1)\n",
    "ax.set_ylim([20, 130])\n",
    "ax.legend(['Admitted', 'Not admitted'], loc='best')\n",
    "ax.set_xlabel('Exam 1 score')\n",
    "ax.set_ylabel('Exam 2 score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data1[['test1', 'test2']].values\n",
    "y = data1.accepted.values\n",
    "n, d = X.shape\n",
    "n, d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k=3\n",
    "result_knn = predictKNN(X,X,y,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax = plotData(data1)\n",
    "ax.set_ylim([20, 130])\n",
    "i = 0\n",
    "for xy in zip(X[:,0],X[:,1]):\n",
    "    ax.annotate('(%s)' % int(result_knn[i]), xy=xy, textcoords='data',size=8)\n",
    "    i += 1\n",
    "ax.set_ylim([20, 130])\n",
    "ax.legend(['Admitted', 'Not admitted'], loc='best')\n",
    "ax.set_xlabel('Exam 1 score')\n",
    "ax.set_ylabel('Exam 2 score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print ('K-nearest neighbors, k = '+str(k)+', training accuracy : ' + str(np.mean(result_knn == y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotData(data1)\n",
    "vis_decision_boundary(X, y, k)\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let's plot the training accuracy when k becomes large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "accuracy_from_dif_k = np.zeros((100,))\n",
    "\n",
    "for dif_k in range(1,100):\n",
    "    result_knn = predictKNN(targetX=X, dataSet=X, labels=y, k=dif_k)\n",
    "    accuracy = np.mean(result_knn == y)\n",
    "    accuracy_from_dif_k[dif_k] = accuracy\n",
    "    \n",
    "#print ('K-nearest neighbors, k = '+str(k)+', training accuracy : ' + str(np.mean(result_knn == y)))    \n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(accuracy_from_dif_k, linewidth=2.0)\n",
    "plt.ylabel('training accuracy',fontsize=15)\n",
    "plt.xlabel('k',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part2. Regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "Let's explore what the data look like via info() which shows the number of data, whether non exists, and data type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('./Hitters.csv').dropna().drop('Unnamed: 0', axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(df[['League', 'Division', 'NewLeague']])\n",
    "dummies.info()\n",
    "print(dummies.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df.Salary\n",
    "\n",
    "# Drop the column with the independent variable (Salary), and columns for which we created dummy variables\n",
    "X_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64')\n",
    "\n",
    "# Define the feature set X.\n",
    "X = pd.concat([X_, dummies[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)\n",
    "\n",
    "# Dataset splitting (Train/Test)\n",
    "X_train, X_test , y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1,shuffle=False)\n",
    "\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Ridge Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn Ridge regression uses linear least squares with L2 regularization.\n",
    "\n",
    "\n",
    "\n",
    "The __sklearn Ridge()__ function has the standard L2 penalty:\n",
    "### $$ \\lambda ||\\theta_1||^2_2 $$\n",
    "\n",
    "In __sklearn Ridge()__ function, it uses hyperparameter 'alpha' which is the same as 'lambda' as we learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "lambdas = 10**np.linspace(5,1,100)*0.5\n",
    "\n",
    "ridge = Ridge()\n",
    "coefs = []\n",
    "\n",
    "scaled_X = StandardScaler().fit_transform(X)\n",
    "\n",
    "for a in lambdas:\n",
    "    ridge.set_params(alpha=a)\n",
    "    ridge.fit(scaled_X, y)\n",
    "    coefs.append(ridge.coef_)\n",
    "\n",
    "vis_coef(lambdas, coefs, method='Ridge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot shows that the Ridge coefficients get larger when we decrease alpha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lambda = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridge2 = Ridge(alpha=4)\n",
    "scaled_X_train = StandardScaler().fit_transform(X_train)\n",
    "scaled_X_test = StandardScaler().fit_transform(X_test)\n",
    "ridge2.fit(scaled_X_train, y_train)\n",
    "pred = ridge2.predict(scaled_X_test)\n",
    "print('MSE : ',mean_squared_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lambda = $10^{10}$ \n",
    "This big penalty shrinks the coefficients to a very large degree and makes the model more biased, resulting in a higher MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ridge2.set_params(alpha=10**10)\n",
    "ridge2.fit(scaled_X_train, y_train)\n",
    "pred = ridge2.predict(scaled_X_test)\n",
    "print('MSE : ',mean_squared_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation for selecting the best lambda(=alpha)\n",
    "#### Implement crossValidation_Ridge to find the best lambda\n",
    "You should return these values/objects correctly.\n",
    "1. MSE_set : MSE list that each element is correspond to the mean squared error of each lambda, i.e. having the same length as the lambdas. \n",
    "2. best_MSE : The lowest MSE of cross validation, which indicates the lambda used for this cv estimation is the best\n",
    "3. best_lambda : Suggested lambda from CV estimation\n",
    "4. test_MSE : MSE estimated on the test data after fitting the model using the whole data and best_lambda\n",
    "5. ridge : The best model we obtained\n",
    "\n",
    "Here, we divide the data into 5 groups, i.e. 5-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MSE_set, best_MSE, best_lambda, test_MSE, ridge= crossValidation_Ridge(lambdas,5, scaled_X_train, y_train,scaled_X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('best lambda : ',best_lambda)\n",
    "print('test MSE : ',test_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vis_mse(lambdas, MSE_set, best_lambda, best_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.Series(ridge2.coef_, index=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For sklearn __Lasso()__ function, the standard L1 penalty is:\n",
    "### $$ \\lambda ||\\theta_1||_1 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso = Lasso(max_iter=10000)\n",
    "coefs_lasso = []\n",
    "\n",
    "for a in lambdas*2:\n",
    "    lasso.set_params(alpha=a)\n",
    "    lasso.fit(scaled_X_train, y_train)\n",
    "    coefs_lasso.append(lasso.coef_)\n",
    "\n",
    "vis_coef(lambdas,coefs_lasso, method='Lasso')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation for selecting best lambda(=alpha)\n",
    "#### Implement crossValidation_Lasso to find the best lambda\n",
    "You should return these values/objects correctly.\n",
    "1. MSE_set : MSE list that each element is correspond to the mean squared error of each lambda, i.e. having the same length as the lambdas. \n",
    "2. best_MSE : The lowest MSE of cross validation, which indicates the lambda used for this cv estimation is the best\n",
    "3. best_lambda : Suggested lambda from CV estimation\n",
    "4. test_MSE : MSE estimated on the test data after fitting the model using the whole data and best_lambda\n",
    "5. lasso : The best model we obtained\n",
    "\n",
    "Here, we divide the data into 5 groups, i.e. 5-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MSE_set_lasso, best_MSE_lasso, best_lambda_lasso, test_MSE_lasso, lasso  = crossValidation_Lasso(lambdas, 5, scaled_X_train, y_train,scaled_X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('best_lambda : ',best_lambda_lasso)\n",
    "print('test_MSE : ',test_MSE_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vis_mse(lambdas,MSE_set_lasso,best_lambda_lasso,best_MSE_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the coefficients of Lasso with the ones of Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some of the coefficients are now reduced to exactly zero.\n",
    "pd.Series(lasso.coef_, index=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
